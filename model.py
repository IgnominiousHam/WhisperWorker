import os
import time
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Common OPUS-MT â†’ English models (major languages)
models = [
    "Helsinki-NLP/opus-mt-fr-en",  # French â†’ English
    "Helsinki-NLP/opus-mt-es-en",  # Spanish â†’ English
    "Helsinki-NLP/opus-mt-de-en",  # German â†’ English
    "Helsinki-NLP/opus-mt-it-en",  # Italian â†’ English
    "Helsinki-NLP/opus-mt-pt-en",  # Portuguese â†’ English
    "Helsinki-NLP/opus-mt-ru-en",  # Russian â†’ English
    "Helsinki-NLP/opus-mt-zh-en",  # Chinese â†’ English
    "Helsinki-NLP/opus-mt-ja-en",  # Japanese â†’ English
    "Helsinki-NLP/opus-mt-ar-en",  # Arabic â†’ English
    "Helsinki-NLP/opus-mt-hi-en",  # Hindi â†’ English
    "Helsinki-NLP/opus-mt-pl-en",  # Polish â†’ English
    "Helsinki-NLP/opus-mt-fi-en",  # Finnish â†’ English
]

print(f"ğŸ“¦ Preparing to download {len(models)} OPUS-MT models...\n")

for model_id in models:
    short = model_id.split("/")[-1]
    try:
        print(f"ğŸ“¥ Downloading {short} ...")
        AutoTokenizer.from_pretrained(model_id)
        AutoModelForSeq2SeqLM.from_pretrained(model_id)
        print(f"âœ… Cached {short}")
        time.sleep(1)
    except Exception as e:
        print(f"âš ï¸ Failed for {short}: {e}")

print("\nğŸ‰ All selected OPUS-MT â†’ English models cached locally!")
print(f"Cache directory: {os.environ.get('TRANSFORMERS_CACHE', '~/.cache/huggingface/')}")
